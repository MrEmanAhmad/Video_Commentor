---
description: 
globs: 
alwaysApply: true
---
# Video Commentary Bot Pipeline Structure

## Pipeline Overview

The video commentary bot processes videos through a 7-step pipeline to generate AI commentary:

1. **Download Video**: [Step_1_download_video.py](mdc:pipeline/Step_1_download_video.py)
   - Uses yt-dlp and Selenium for cookie extraction
   - Handles YouTube, Twitter, and direct video URLs

2. **Extract Frames**: [Step_2_extract_frames.py](mdc:pipeline/Step_2_extract_frames.py)
   - Uses OpenCV for frame extraction
   - Implements scene change detection and motion analysis

3. **Analyze Frames**: [Step_3_analyze_frames.py](mdc:pipeline/Step_3_analyze_frames.py)
   - Uses Google Vision API for object detection and labeling
   - Uses Qwen Vision API for detailed scene understanding (replacing OpenAI)
   - `VisionAnalyzer` class orchestrates the analysis process

4. **Generate Commentary**: [Step_4_generate_commentary.py](mdc:pipeline/Step_4_generate_commentary.py)
   - Uses Qwen LLMs for English commentary generation
   - Uses OpenAI exclusively for translation to non-English languages
   - Supports multiple commentary styles (news, funny, nature, etc.)

5. **Generate Audio**: [Step_5_generate_audio.py](mdc:pipeline/Step_5_generate_audio.py)
   - Uses Google TTS for speech synthesis with extensive voice options
   - Handles both English and Urdu with language-specific processing
   - Applies SSML formatting for natural speech

6. **Generate Video**: [Step_6_video_generation.py](mdc:pipeline/Step_6_video_generation.py)
   - Uses FFmpeg to combine video with generated audio
   - Handles video sizing, padding, and audio mixing

7. **Cleanup**: [Step_7_cleanup.py](mdc:pipeline/Step_7_cleanup.py)
   - Removes temporary files and directories
   - Preserves final output videos

## API and Provider Options

### Image Analysis
- **Current**: Google Vision API + OpenAI Vision API
- **Proposed**: Google Vision API + Qwen Vision API (replacing OpenAI)
- **API Base URL**: `https://dashscope-intl.aliyuncs.com/compatible-mode/v1`
- **Model**: `qwen-vl-plus`

### Commentary Generation
- **Current**: OpenAI LLMs
- **Proposed**: 
  - Qwen LLMs for English commentary
  - OpenAI exclusively for translation to non-English languages
- **API Options**:
  - OpenAI-compatible: `https://dashscope-intl.aliyuncs.com/compatible-mode/v1`
  - DashScope native: `https://dashscope-intl.aliyuncs.com/api/v1`
- **Models**:
  - Text: `qwen-plus`, `qwen-max`, `qwen-turbo`
  - Vision: `qwen-vl-plus`, `qwen-vl-max`

### Text-to-Speech Options (Google TTS)
- **Voice Types**:
  - Standard: Basic quality voices
  - WaveNet: Enhanced, more natural-sounding voices
  - Neural2: Highest quality voices with natural intonation (English)

- **English Voices**:
  - American English (en-US): Standard, WaveNet and Neural2, multiple gender options
  - British English (en-GB): Standard, WaveNet and Neural2, multiple gender options
  - Australian English (en-AU): Standard and WaveNet, multiple gender options

- **Urdu Voices**:
  - Standard: ur-PK-Standard-A through D (male and female options)
  - WaveNet: ur-PK-Wavenet-A and B (higher quality)
  
- **SSML Support**:
  - Pauses, emphasis, and prosody control
  - Language-specific formatting

## Prompt Management

- [prompts.py](mdc:pipeline/prompts.py) centralizes prompt templates and LLM provider logic
- Currently supports OpenAI and DeepSeek providers; will add Qwen
- Defines commentary styles and speech patterns for different content types

## Enhancement Plan: Qwen Integration

### Image Analysis
- Replace OpenAI Vision with Qwen for all image analysis
- Use OpenAI only for translation to non-English languages
- Implement via OpenAI-compatible interface with `qwen-vl-plus` model

### Commentary Generation
- Use Qwen as the exclusive LLM for English commentary
- Use OpenAI exclusively for translation when non-English output is requested
- Add Qwen as provider in `PromptManager`

### Voice Selection Enhancement
- Implement dynamic voice selection function based on language, gender, and quality preferences
- Expose voice options to users through configuration
- Maintain Google TTS for all languages with optimal voice selection

### Pipeline Improvements
- Abstract vision and LLM providers behind common interfaces
- Centralize language handling and translation logic
- Improve error handling with provider-aware fallbacks
- Make provider and voice selection configurable by users




