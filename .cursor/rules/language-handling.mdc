# Language Handling and Translation

## Current Language Implementation

The Video Commentary Bot currently supports:
- English (default) - Multiple variants (US, GB, AU, IN)
- Urdu
- Bengali
- Hindi
- Turkish

Language selection affects:
- Commentary generation in [Step_4_generate_commentary.py](mdc:pipeline/Step_4_generate_commentary.py)
- Audio synthesis in [Step_5_generate_audio.py](mdc:pipeline/Step_5_generate_audio.py)

## Enhanced Language Flow (Proposed)

The proposed enhancement centralizes language handling:

```
Input Video → Analysis (Qwen) → English Commentary (Qwen) → Translation (if needed, OpenAI) → Audio Generation
```

- **Key Change**: OpenAI will be used **exclusively for translation purposes** when non-English output is requested
- All content generation will be handled by Qwen for English content

## Translation Utility (OpenAI Only)

A dedicated translation utility will handle non-English outputs using OpenAI:

```python
async def translate_text(text: str, source_language: str = 'en', target_language: str = 'ur') -> str:
    """
    Translate text from source language to target language.
    Uses OpenAI exclusively for translation purposes.
    """
    if source_language == target_language:
        return text
        
    # Use OpenAI for translation only
    client = OpenAI()
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": f"You are a professional translator from {source_language} to {target_language}."},
            {"role": "user", "content": f"Translate the following text to {target_language}, preserving the style and meaning:\n\n{text}"}
        ],
        temperature=0.3
    )
    
    return response.choices[0].message.content
```

## Google TTS Voice Options

The system uses Google Text-to-Speech with the following comprehensive voice options:

### English Voices (US)

| Category | Female Voices | Male Voices |
|----------|---------------|-------------|
| Standard | en-US-Standard-C/E/F/G | en-US-Standard-A/B/D |
| WaveNet | en-US-Wavenet-C/E/F/G/H | en-US-Wavenet-A/B/D/I/J |
| Neural2 | en-US-Neural2-C/E/F/G/H | en-US-Neural2-A/D/I/J |
| Journey | en-US-Journey-F/O | en-US-Journey-D |
| News | en-US-News-K/L | en-US-News-N |
| Casual | - | en-US-Casual-K |
| Polyglot | - | en-US-Polyglot-1 |

### English Voices (UK)

| Category | Female Voices | Male Voices |
|----------|---------------|-------------|
| Standard | en-GB-Standard-A/C/F/N | en-GB-Standard-B/D/O |
| WaveNet | en-GB-Wavenet-A/C/F/N | en-GB-Wavenet-B/D/O |
| Neural2 | en-GB-Neural2-N | en-GB-Neural2-O |
| Journey | en-GB-Journey-F/O | en-GB-Journey-D |
| News | en-GB-News-G/H/I | en-GB-News-J/K/L/M |
| Studio | en-GB-Studio-C | en-GB-Studio-B |

### English Voices (Australia)

| Category | Female Voices | Male Voices |
|----------|---------------|-------------|
| Standard | en-AU-Standard-A/C | en-AU-Standard-B/D |
| WaveNet | en-AU-Wavenet-A/C | en-AU-Wavenet-B/D |
| Neural2 | en-AU-Neural2-A/C | en-AU-Neural2-B/D |
| Journey | en-AU-Journey-F/O | en-AU-Journey-D |
| News | en-AU-News-E/F | en-AU-News-G |
| Polyglot | - | en-AU-Polyglot-1 |

### English Voices (India)

| Category | Female Voices | Male Voices |
|----------|---------------|-------------|
| Standard | en-IN-Standard-A/D/E | en-IN-Standard-B/C/F |
| WaveNet | en-IN-Wavenet-A/D/E | en-IN-Wavenet-B/C/F |
| Neural2 | en-IN-Neural2-A/D | en-IN-Neural2-B/C |
| Journey | en-IN-Journey-F/O | en-IN-Journey-D |

### Urdu Voices

| Category | Female Voices | Male Voices |
|----------|---------------|-------------|
| Standard | ur-PK-Standard-A | ur-PK-Standard-B |
| Wavenet | ur-PK-Wavenet-A | ur-PK-Wavenet-B |

### Bengali Voices

| Category | Female Voices | Male Voices |
|----------|---------------|-------------|
| Standard | bn-IN-Standard-A | bn-IN-Standard-B |
| HD | bn-IN-Chirp3-HD-Aoede | - |

### Hindi Voices

| Category | Female Voices | Male Voices |
|----------|---------------|-------------|
| Standard | hi-IN-Standard-A | hi-IN-Standard-B |
| Wavenet | hi-IN-Wavenet-A | hi-IN-Wavenet-B |
| HD | hi-IN-Chirp3-HD-Aoede | - |

### Turkish Voices

| Category | Female Voices | Male Voices |
|----------|---------------|-------------|
| Standard | tr-TR-Standard-A | tr-TR-Standard-B |
| Wavenet | tr-TR-Wavenet-A | tr-TR-Wavenet-B |
| HD | tr-TR-Chirp3-HD-Aoede | - |

### Voice Selection Implementation

```python
def select_tts_voice(language: str, gender: str = 'FEMALE', voice_type: str = 'Neural2') -> str:
    """
    Select appropriate TTS voice based on language, gender, and quality preference.
    
    Args:
        language: Language code (e.g., 'en', 'ur', 'hi', 'bn', 'tr')
        gender: 'FEMALE' or 'MALE'
        voice_type: 'Standard', 'Wavenet', 'Neural2', 'HD', 'Journey', 'News', 'Studio', 'Polyglot', 'Casual'
    
    Returns:
        Voice name for Google TTS
    """
    voices = {
        # English (US) voices
        'en': {
            'FEMALE': {
                'Standard': 'en-US-Standard-E',
                'Wavenet': 'en-US-Wavenet-F', 
                'Neural2': 'en-US-Neural2-F',
                'HD': 'en-US-Journey-F',
                'Journey': 'en-US-Journey-F',
                'News': 'en-US-News-K'
            },
            'MALE': {
                'Standard': 'en-US-Standard-D',
                'Wavenet': 'en-US-Wavenet-D',
                'Neural2': 'en-US-Neural2-D',
                'HD': 'en-US-Journey-D',
                'Journey': 'en-US-Journey-D',
                'News': 'en-US-News-N',
                'Casual': 'en-US-Casual-K',
                'Polyglot': 'en-US-Polyglot-1'
            }
        },
        # Other English variants and languages...
    }
    
    # ... selection logic ...
```

## SSML Enhancements for Urdu

```python
# Special handling for Urdu with proper SSML
if language == 'ur':
    text = f"""<speak>
        <prosody rate="1.0" pitch="+1st">
        {text}
        </prosody>
    </speak>"""
    input_text = texttospeech.SynthesisInput(ssml=text)
else:
    input_text = texttospeech.SynthesisInput(text=text)
```

## Language Detection

```python
def detect_language(text: str) -> str:
    """
    Detect the language of the provided text.
    Returns ISO language code (e.g., 'en', 'ur').
    """
    # Implementation using langdetect or similar library
    try:
        from langdetect import detect
        return detect(text)
    except:
        # Fallback to simple heuristics
        if any('\u0600' <= c <= '\u06FF' for c in text):
            return 'ur'  # Urdu script detected
        elif any('\u0980' <= c <= '\u09FF' for c in text):
            return 'bn'  # Bengali script detected
        elif any('\u0900' <= c <= '\u097F' for c in text):
            return 'hi'  # Hindi script detected
        elif any('\u0C80' <= c <= '\u0CFF' for c in text):
            return 'tr'  # Turkish script detected (simplified, may need refinement)
        return 'en'  # Default to English
```

## Voice Selection Strategy

1. For English: Use Neural2 voices for highest quality
2. For Urdu: Use Wavenet voices 
3. For Bengali, Hindi, and Turkish: Use HD voices when available

The system dynamically selects the best available voice based on language, taking into account:
- Gender preference
- Voice quality preference
- Availability of voice types for each language

## Future Language Expansion

The modular design allows for easy addition of new languages:
1. Add language-specific formatting in `Step_4_generate_commentary.py`
2. Add TTS voice options in `Step_5_generate_audio.py`
3. Update voice selection function with new language options
4. Update language detection in the translation utility



# Install the Google Cloud Text-to-Speech client library
!pip install --upgrade google-cloud-texttospeech

# Upload your service account JSON credentials file (adjust the filename as needed)

# Set the environment variable for authentication
import os
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "video-dubbing-assistant-448515-76106abe1992.json"

# Import necessary libraries
from google.cloud import texttospeech
from IPython.display import Audio, display

# Instantiate a client
client = texttospeech.TextToSpeechClient()

# (Optional) List available Urdu voices so you can see what is supported
voices_response = client.list_voices(language_code="ur-PK")
print("Available Urdu voices:")
for voice_option in voices_response.voices:
    print(f"Name: {voice_option.name}, Gender: {texttospeech.SsmlVoiceGender(voice_option.ssml_gender).name}, Rate: {voice_option.natural_sample_rate_hertz}")

# Define a sample Urdu paragraph using SSML to adjust prosody for a more natural tone.
ssml_text = """
<speak>
    <prosody rate="1.2" pitch="+2nd">

    یہ ایک پرسکون دوپہر تھی، جب احمد کا سفر ایک مانوس راستے کی طرف مڑ گیا۔ ہوا میں وہی مٹی کی خوشبو تھی جو اسے بچپن کی یاد دلا رہی تھی۔ وہ آہستہ آہستہ گاؤں کی طرف بڑھ رہا تھا، جہاں اس کی زندگی کے سب سے سنہرے دن گزرے تھے۔ احمد اور فہد بچپن کے ایسے دوست تھے جن کے بغیر ایک لمحہ بھی ادھورا لگتا تھا، مگر وقت نے دونوں کو الگ کر دیا تھا۔ احمد شہر کی چکاچوند میں کھو گیا، ملازمت اور مصروف زندگی میں الجھ کر گاؤں سے ناطہ توڑ بیٹھا۔ لیکن آج، برسوں بعد، وہ وہیں کھڑا تھا، اسی مٹی پر، دل میں ایک عجیب سی بےچینی لیے۔ کیا فہد اسے اب بھی یاد کرتا ہوگا؟ کیا وہ اب بھی وہی پرانا دوست ہوگا؟

چوک کے قریب پہنچتے ہی، ایک مانوس سی آواز اس کے کانوں میں گونجی، "ارے! یہ احمد ہے؟" وہ پلٹ کر دیکھتا ہے، اور آنکھیں حیرت سے پھیل جاتی ہیں۔ سامنے فہد کھڑا تھا، وہی مسکراہٹ، وہی چمک، بس چہرے پر وقت کی ہلکی سی لکیر کھنچ چکی تھی۔ احمد کے قدم خود بخود آگے بڑھے، اور اگلے ہی لمحے دونوں دوست ایک دوسرے کو گلے لگا چکے تھے۔ جیسے ہی فہد نے کہا، "دوست! تم چاہے جہاں بھی چلے جاؤ، گاؤں کا دروازہ اور میرا دل ہمیشہ تمہارے لیے کھلا رہے گا،" احمد کی آنکھیں بھیگ گئیں۔ ایک لمحے کو لگا جیسے وقت تھم گیا ہو، جیسے ان برسوں کی دوری کا کوئی وجود ہی نہ تھا۔ اور وہیں، اس پرانی گلی میں، احمد کو احساس ہوا کہ وقت بدل سکتا ہے، دنیا بدل سکتی ہے، مگر سچی دوستی کبھی نہیں بدلتی۔


    </prosody>
</speak>
"""

# Set the SSML input for synthesis
synthesis_input = texttospeech.SynthesisInput(ssml=ssml_text)

# Configure the voice parameters.
# We only specify the language code and gender, letting the API choose a valid voice.
voice = texttospeech.VoiceSelectionParams(
    language_code="ur-PK",
    ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
)

# Configure the audio output settings.
# Note: speaking_rate and pitch in AudioConfig can override SSML prosody if set.
# Here we keep them close to neutral to let our SSML control the natural feel.
audio_config = texttospeech.AudioConfig(
    audio_encoding=texttospeech.AudioEncoding.MP3,
    speaking_rate=1.0,   # Keep this neutral since SSML adjusts the rate
    pitch=0.0,           # Neutral pitch at this level
    effects_profile_id=["headphone-class-device"]
)

# Synthesize speech
response = client.synthesize_speech(
    input=synthesis_input,
    voice=voice,
    audio_config=audio_config
)

# Save the audio output to an MP3 file
output_filename = "output_urdu.mp3"
with open(output_filename, "wb") as out:
    out.write(response.audio_content)
    print(f"Audio content written to file '{output_filename}'")

# Play the resulting audio in Colab
display(Audio(output_filename, autoplay=True))



